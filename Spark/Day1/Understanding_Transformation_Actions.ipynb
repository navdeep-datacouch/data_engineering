{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153596a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ColabSparkSession\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c151edb-8900-4220-9c44-d466821706ea",
   "metadata": {},
   "source": [
    "<font color=\"orange\"><b>Transformations are Lazily Evaluated.</b></font>\n",
    "\n",
    "\n",
    "<b>Lazy evaluation</b> means that Spark does not evaluate each transformation as they arrive, but instead queues them together and evaluate all at once, as an Action is called. The benefit of this approach is that Spark can make optimization decisions after it had a chance to look at the DAG in entirety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc3e45-638b-412b-808d-33c04d27f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Check your Spark UI through Application Master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1118e-ef7e-49ab-ad74-09342a56c792",
   "metadata": {},
   "source": [
    "Let's create a Dataframe from a csv file called ratings which has movies ratings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d236ed46-3942-47dc-8d67-1768a6ccdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDF = spark.read.option(\"header\",\"true\").csv(\"spark-data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa923e1-b41c-40de-8e79-c5e1710df279",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404bd6a-0e96-4291-a533-ff466fa1ec66",
   "metadata": {},
   "source": [
    "Now run above code , check Spark UI, you will notice a job because of above code because .csv is an action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ce3f8-7e30-4f99-8568-108d07c10189",
   "metadata": {},
   "source": [
    "Let's add filter transformtions to filter out movies whose ratings greater than 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2f09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "\n",
    "orderDF = ratingDF \\\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(\"float\")) \\\n",
    "    .filter(col(\"rating\") > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f5439d-fcd8-4e56-b248-e7c66a9e3b83",
   "metadata": {},
   "source": [
    "Check out your Spark UI, Did you notice , no job appeared in your Spark UI because of above code\n",
    "\n",
    "Why?\n",
    "\n",
    "Absolutely. because above code is just a transformation with no action. So nothing is submitted to Spark Cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68105d-5fb8-4f5d-8a3f-224e8761a8cd",
   "metadata": {},
   "source": [
    "<b> Now Let's add some Action </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54536a-3bd5-4d4b-a6b9-450b4bd3d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderDF.foreach(lambda x: None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6ce74-2767-458b-b0ac-4366b876c661",
   "metadata": {},
   "source": [
    "Check out your Spark UI, did you notice a new Job? \n",
    "\n",
    "<b>Hurray!!!</b> which means we now understand that code is triggered in Spark only when action is encountered and transformations are lazily evaulated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35719459-d9c6-4346-936b-e20564d19aba",
   "metadata": {},
   "source": [
    "### <font color=\"orange\"> <b> Assignment </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d523ab-0bea-45b9-89b5-8e1bbcd0f575",
   "metadata": {},
   "source": [
    "Run below code and check out Spark UI. Can you figure out what is problem with below code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac435d70-6ac6-4935-b8a0-b58917fef3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",\"true\").csv(\"spark-data/ratings.csv\") \\\n",
    ".filter((\"rating\") > 3) \\\n",
    ".groupBy(\"rating\") \\\n",
    ".count() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
