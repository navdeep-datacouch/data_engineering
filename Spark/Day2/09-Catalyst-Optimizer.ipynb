{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuMK14XJWjyj"
   },
   "source": [
    "# Catalyst Optimizer\n",
    "\n",
    "**Technical Accomplishments:**\n",
    "* Understanding about what is the Catalyst Optimizer?\n",
    "* Understanding the different stages of the Catalyst Optimizer\n",
    "* Example of Physical Plan Optimization (x2)\n",
    "* Example of Predicate Pushdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B7iBj1l1Wjyy"
   },
   "outputs": [],
   "source": [
    "# Because we will need it later...\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ColabSparkSession\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSB0IEQ-Wjyz"
   },
   "source": [
    "## Catalyst Optimizer\n",
    "\n",
    "* Catalyst Optimize is the fundamental to the `SQL` and `DataFrames` API.\n",
    "* It is an **extensible query optimizer**.\n",
    "* It actually contains a **general library for representing trees and applying rules** to manipulate them.\n",
    "* Several public extension points, including external data sources and user-defined types.\n",
    "\n",
    "<a href=\"https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html\" target=\"_blank\">Deep Dive into Spark SQLâ€™s Catalyst Optimizer</a> (April 13, 2015)\n",
    "\n",
    "Processing is broken down into several stages as we can see here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqIoJhj3Wjy1"
   },
   "source": [
    "![Catalyst](https://files.training.databricks.com/images/105/catalyst-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9T-7bApWjy2"
   },
   "source": [
    "## Optimized Logical Plan\n",
    "\n",
    "**Rewriting our code** is one of the many optimizations performed by the Catalyst Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuL4jPu1Wjy2"
   },
   "source": [
    "### Example #1: Multiple Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "ratingDF = spark \\\n",
    ".read \\\n",
    ".parquet(\"spark-data/rating-huge\") \\\n",
    ".filter(col(\"rating\") == \"3.0\") \\\n",
    ".filter(col(\"movieId\") == \"1000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iS5DewSrWjy8",
    "outputId": "5d06e4ac-f449-4109-e439-00a611fb4ef0"
   },
   "outputs": [],
   "source": [
    "ratingDF.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXEmulRyWjy8"
   },
   "source": [
    "## Projection Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5sEExgmWjy9",
    "outputId": "36b30b92-6665-4de5-f651-9aad356ef9a5"
   },
   "outputs": [],
   "source": [
    "ratingDF1 = spark \\\n",
    ".read \\\n",
    ".parquet(\"spark-data/rating-huge\") \\\n",
    ".filter(col(\"rating\") > 3.0) \\\n",
    ".filter(col(\"movieId\") == \"1000\") \\\n",
    ".groupBy(\"rating\") \\\n",
    ".count() \\\n",
    ".filter(col(\"rating\") < 2)  \\\n",
    ".explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t88vNg4Wjy_"
   },
   "source": [
    "***Note:*** `explain()` is not the only way to get access to this level of detail.<br/>\n",
    "But, we can also see it in the **Spark UI**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sfu9I72TWjy_"
   },
   "source": [
    "## Columnar Predicate Pushdown\n",
    "\n",
    "It takes place when a filter can be pushed down to the original data source, such as the database server.\n",
    "\n",
    "For this example, we are going to compare `DataFrames` from two different sources:\n",
    "* Parquet - where a predicate pushdown **WILL** take place.\n",
    "* CSV - where a predicate pushdown will **NOT** take place.\n",
    "\n",
    "In each case, we can see evidence of the pushdown (or lack of it) in the **Physical Plan**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Example #1: CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingCsVDF = spark.read.option(\"header\",\"true\").option(\"inferschema\",\"true\").csv(\"spark-data/ratings.csv\") \n",
    "ratingCsVDF.printSchema()\n",
    "ratingCsVDF.filter(\"userId =1\").explain(\"Formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingCsVDF.write.mode(\"overwrite\").csv(\"spark-data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingCsVDF.filter(\"userId =1\").write.mode(\"overwrite\").csv(\"spark-data/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example2: Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingJsonDF = spark.read.json(\"spark-data/rating-json\")\n",
    "ratingJsonDF.printSchema()\n",
    "ratingJsonDF.explain(\"Formatted\")\n",
    "ratingJsonDF.filter(col(\"userId\") == 1).write.mode(\"overwrite\").csv(\"spark-data/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZsfFIa0WjzA"
   },
   "source": [
    "### Example #3: Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtNFMNEoWjzC"
   },
   "outputs": [],
   "source": [
    "ratingParquetDF = spark.read.parquet(\"spark-data/rating-huge\") \n",
    "ratingParquetDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingParquetDF.filter(col(\"userId\") == 1).explain(\"Formatted\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingParquetDF.filter(col(\"userId\") == 1).write.mode(\"overwrite\").csv(\"spark-data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingParquetDF1 = spark.read.parquet(\"spark-data/rating-typed\")\n",
    "ratingParquetDF1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingParquetDF1.filter(col(\"userId\") == 1).explain(\"Formatted\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingParquetDF1.filter(col(\"userId\") == 1).write.mode(\"overwrite\").csv(\"spark-data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingParquetDF1.filter(col(\"rating\") == 3.5).write.mode(\"overwrite\").csv(\"spark-data/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Y8n2Fm8WjzJ",
    "outputId": "0c74782c-690d-4255-e8b5-f22539e5b023"
   },
   "outputs": [],
   "source": [
    "ratingParquetDF1.filter(col(\"rating\") == 3.5).explain(\"Formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingCSV.withColumn(\"newRating\", lit(1+2)).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQWjN4dVWjzJ"
   },
   "source": [
    "## End of Exercise"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09-Catalyst-Optimizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "name": "Catalyst Optimizer",
  "notebookId": 9651
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
